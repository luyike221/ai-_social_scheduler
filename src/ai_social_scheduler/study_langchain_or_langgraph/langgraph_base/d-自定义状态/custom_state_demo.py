"""
è‡ªå®šä¹‰çŠ¶æ€æ¼”ç¤º

æœ¬æ•™ç¨‹å±•ç¤ºäº†å¦‚ä½•åœ¨ LangGraph ä¸­å‘çŠ¶æ€æ·»åŠ é¢å¤–çš„å­—æ®µï¼Œä»¥å®šä¹‰å¤æ‚çš„è¡Œä¸ºã€‚
èŠå¤©æœºå™¨äººå°†ä½¿ç”¨æœç´¢å·¥å…·æŸ¥æ‰¾ç‰¹å®šä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬å‘ç»™äººå·¥è¿›è¡Œå®¡æŸ¥ã€‚

ä¸»è¦ç‰¹æ€§ï¼š
1. å‘çŠ¶æ€æ·»åŠ è‡ªå®šä¹‰é”®ï¼ˆname å’Œ birthdayï¼‰
2. åœ¨å·¥å…·å†…éƒ¨æ›´æ–°çŠ¶æ€ï¼ˆä½¿ç”¨ Commandï¼‰
3. ä½¿ç”¨ interrupt è¿›è¡Œäººå·¥å¹²é¢„
4. æ‰‹åŠ¨æ›´æ–°çŠ¶æ€ï¼ˆä½¿ç”¨ graph.update_stateï¼‰

æ‰§è¡Œå‘½ä»¤ï¼š
uv run python -m ai_social_scheduler.study_langchain_or_langgraph.langgraph_base.04-è‡ªå®šä¹‰çŠ¶æ€.custom_state_demo
"""

from typing import Annotated

from langchain_core.messages import ToolMessage
from langchain_core.tools import InjectedToolCallId, tool
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.types import Command, interrupt
from typing_extensions import TypedDict

from ....client import QwenClient


# ==================== 1. å‘çŠ¶æ€æ·»åŠ é”® ====================

class State(TypedDict):
    """
    çŠ¶æ€å®šä¹‰
    
    é€šè¿‡å‘çŠ¶æ€æ·»åŠ  name å’Œ birthday é”®æ¥æ›´æ–°èŠå¤©æœºå™¨äººï¼Œä»¥ç ”ç©¶å®ä½“çš„ç”Ÿæ—¥ã€‚
    è¿™äº›ä¿¡æ¯ä½¿å…¶ä»–å›¾èŠ‚ç‚¹ï¼ˆä¾‹å¦‚å­˜å‚¨æˆ–å¤„ç†ä¿¡æ¯çš„ä¸‹æ¸¸èŠ‚ç‚¹ï¼‰ä»¥åŠå›¾çš„æŒä¹…å±‚æ˜“äºè®¿é—®ã€‚
    """
    messages: Annotated[list, add_messages]
    name: str
    birthday: str


# ==================== 2. å®šä¹‰å·¥å…· ====================

@tool
def tavily_search_results_json(query: str) -> str:
    """
    Mock Tavily ç½‘é¡µæœç´¢å¼•æ“å·¥å…·
    
    è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„ Tavily æœç´¢å¼•æ“ï¼Œè¿”å›æ¨¡æ‹Ÿçš„æœç´¢ç»“æœã€‚
    åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨çœŸå®çš„ Tavily APIã€‚
    
    Args:
        query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
    
    Returns:
        str: JSON æ ¼å¼çš„æœç´¢ç»“æœå­—ç¬¦ä¸²
    """
    import json
    
    # Mock æœç´¢ç»“æœæ•°æ®
    mock_results = {
        "LangGraph release date": [
            {
                "url": "https://blog.langchain.ac.cn/langgraph-cloud/",
                "content": "We also have a new stable release of LangGraph. By LangChain 6 min read Jun 27, 2024 (Oct '24) Edit: Since the launch of LangGraph Platform, we now have multiple deployment options alongside LangGraph Studio - which now fall under LangGraph Platform. LangGraph Platform is synonymous with our Cloud SaaS deployment option."
            },
            {
                "url": "https://changelog.langchain.ac.cn/announcements/langgraph-cloud-deploy-at-scale-monitor-carefully-iterate-boldly",
                "content": "LangChain - Changelog | â˜ ğŸš€ LangGraph Platform: Deploy at scale, monitor LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain Changelog Sign up for our newsletter to stay up to date DATE: The LangChain Team LangGraph LangGraph Platform â˜ ğŸš€ LangGraph Platform: Deploy at scale, monitor carefully, iterate boldly DATE: June 27, 2024 AUTHOR: The LangChain Team LangGraph Platform is now in closed beta, offering scalable, fault-tolerant deployment for LangGraph agents. LangGraph Platform also includes a new playground-like studio for debugging agent failure modes and quick iteration: Join the waitlist today for LangGraph Platform. And to learn more, read our blog post announcement or check out our docs. Subscribe By clicking subscribe, you accept our privacy policy and terms and conditions."
            }
        ],
    }
    
    # æ ¹æ®æŸ¥è¯¢å…³é”®è¯åŒ¹é…ç»“æœ
    query_lower = query.lower()
    results = []
    
    # ç®€å•çš„å…³é”®è¯åŒ¹é…é€»è¾‘
    if "langgraph" in query_lower and ("release" in query_lower or "date" in query_lower):
        results = mock_results.get("LangGraph release date", [])
    else:
        # é»˜è®¤è¿”å›é€šç”¨ç»“æœ
        results = [
            {
                "url": "https://www.example.com/search",
                "content": f"è¿™æ˜¯å…³äº '{query}' çš„æ¨¡æ‹Ÿæœç´¢ç»“æœã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè¿”å›çœŸå®çš„ç½‘é¡µæœç´¢ç»“æœã€‚"
            }
        ]
    
    # è¿”å› JSON æ ¼å¼çš„å­—ç¬¦ä¸²
    return json.dumps(results, ensure_ascii=False, indent=2)


@tool
def human_assistance(
    name: str, 
    birthday: str, 
    tool_call_id: Annotated[str, InjectedToolCallId]
):
    """
    è¯·æ±‚äººå·¥ååŠ©
    
    è¿™ä¸ªå·¥å…·ä¼šä¸­æ–­æ‰§è¡Œï¼Œç­‰å¾…äººå·¥å®¡æŸ¥ä¿¡æ¯ã€‚
    å¦‚æœä¿¡æ¯æ­£ç¡®ï¼Œåˆ™æ›´æ–°çŠ¶æ€ï¼›å¦åˆ™ï¼Œæ¥æ”¶äººå·¥æä¾›çš„ä¿®æ­£ä¿¡æ¯ã€‚
    
    æ³¨æ„ï¼šå› ä¸ºæˆ‘ä»¬è¦ç”Ÿæˆä¸€ä¸ªç”¨äºçŠ¶æ€æ›´æ–°çš„ ToolMessageï¼Œ
    æ‰€ä»¥é€šå¸¸éœ€è¦å¯¹åº”å·¥å…·è°ƒç”¨çš„ IDã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ LangChain çš„
    InjectedToolCallId æ¥æ ‡è®°è¿™ä¸ªå‚æ•°ä¸åº”è¯¥åœ¨å·¥å…·çš„æ¨¡å¼ä¸­å‘æ¨¡å‹æ˜¾ç¤ºã€‚
    
    Args:
        name: å®ä½“åç§°
        birthday: ç”Ÿæ—¥ä¿¡æ¯
        tool_call_id: å·¥å…·è°ƒç”¨ IDï¼ˆç”± LangChain è‡ªåŠ¨æ³¨å…¥ï¼‰
    
    Returns:
        Command: åŒ…å«çŠ¶æ€æ›´æ–°çš„ Command å¯¹è±¡
    """
    # ä¸­æ–­æ‰§è¡Œï¼Œç­‰å¾…äººå·¥å“åº”
    human_response = interrupt(
        {
            "question": "Is this correct?",
            "name": name,
            "birthday": birthday,
        },
    )
    
    # å¦‚æœä¿¡æ¯æ­£ç¡®ï¼ŒæŒ‰åŸæ ·æ›´æ–°çŠ¶æ€
    if human_response.get("correct", "").lower().startswith("y"):
        verified_name = name
        verified_birthday = birthday
        response = "Correct"
    # å¦åˆ™ï¼Œæ¥æ”¶äººå·¥å®¡æŸ¥è€…æä¾›çš„ä¿¡æ¯
    else:
        verified_name = human_response.get("name", name)
        verified_birthday = human_response.get("birthday", birthday)
        response = f"Made a correction: {human_response}"
    
    # è¿™æ¬¡æˆ‘ä»¬åœ¨å·¥å…·å†…éƒ¨æ˜¾å¼åœ°ä½¿ç”¨ ToolMessage æ›´æ–°çŠ¶æ€
    state_update = {
        "name": verified_name,
        "birthday": verified_birthday,
        "messages": [ToolMessage(response, tool_call_id=tool_call_id)],
    }
    
    # æˆ‘ä»¬åœ¨å·¥å…·ä¸­è¿”å›ä¸€ä¸ª Command å¯¹è±¡æ¥æ›´æ–°æˆ‘ä»¬çš„çŠ¶æ€
    return Command(update=state_update)


# ==================== 3. åˆ›å»º StateGraph ====================

def create_custom_state_graph():
    """
    åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çŠ¶æ€çš„å›¾
    
    Returns:
        CompiledGraph: ç¼–è¯‘åçš„å›¾ï¼ˆæ”¯æŒè‡ªå®šä¹‰çŠ¶æ€å’Œäººå·¥å¹²é¢„ï¼‰
    """
    # åˆ›å»ºå›¾æ„å»ºå™¨
    graph_builder = StateGraph(State)
    
    # ==================== 4. åˆå§‹åŒ– LLM ====================
    # ä½¿ç”¨ QwenClientï¼ˆé€šä¹‰åƒé—®ï¼‰ä½œä¸º LLM
    qwen_client = QwenClient(
        model="qwen-plus",
        temperature=0.7,
    )
    llm = qwen_client.client
    
    # ==================== 5. å‡†å¤‡å·¥å…· ====================
    tools = [tavily_search_results_json, human_assistance]
    
    # å°†å·¥å…·ç»‘å®šåˆ° LLM
    llm_with_tools = llm.bind_tools(tools)
    
    # ==================== 6. æ·»åŠ èŠ‚ç‚¹ ====================
    
    def chatbot(state: State):
        """
        èŠå¤©æœºå™¨äººèŠ‚ç‚¹
        
        è¿™ä¸ªèŠ‚ç‚¹æ¥æ”¶å½“å‰çŠ¶æ€ä½œä¸ºè¾“å…¥ï¼Œè°ƒç”¨ LLM ç”Ÿæˆå“åº”ã€‚
        å¦‚æœ LLM å†³å®šéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå®ƒä¼šåœ¨å“åº”ä¸­åŒ…å« tool_callsã€‚
        
        Args:
            state: å½“å‰çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯åˆ—è¡¨ã€name å’Œ birthday
        
        Returns:
            dict: åŒ…å«æ–°æ¶ˆæ¯çš„çŠ¶æ€æ›´æ–°
        """
        # è°ƒç”¨ LLMï¼Œä¼ å…¥å½“å‰çš„æ‰€æœ‰æ¶ˆæ¯
        message = llm_with_tools.invoke(state["messages"])
        # ç¡®ä¿æ¯æ¬¡åªæœ‰ä¸€ä¸ªå·¥å…·è°ƒç”¨
        assert len(message.tool_calls) <= 1
        return {"messages": [message]}
    
    # æ·»åŠ  chatbot èŠ‚ç‚¹
    graph_builder.add_node("chatbot", chatbot)
    
    # ==================== 7. æ·»åŠ å·¥å…·èŠ‚ç‚¹ ====================
    # ä½¿ç”¨ LangGraph é¢„æ„å»ºçš„ ToolNode
    tool_node = ToolNode(tools=tools)
    graph_builder.add_node("tools", tool_node)
    
    # ==================== 8. å®šä¹‰è¾¹å’Œæ¡ä»¶è¾¹ ====================
    
    # ä» START åˆ° chatbot çš„è¾¹
    graph_builder.add_edge(START, "chatbot")
    
    # ä» chatbot åˆ°å…¶ä»–èŠ‚ç‚¹çš„æ¡ä»¶è¾¹
    graph_builder.add_conditional_edges(
        "chatbot",
        tools_condition,
    )
    
    # ä» tools å›åˆ° chatbot çš„è¾¹
    graph_builder.add_edge("tools", "chatbot")
    
    # ==================== 9. ç¼–è¯‘å›¾ï¼ˆå¯ç”¨æ£€æŸ¥ç‚¹ï¼‰====================
    memory = MemorySaver()
    graph = graph_builder.compile(checkpointer=memory)
    
    return graph


# ==================== 10. è¿è¡Œç¤ºä¾‹ ====================

def run_example():
    """
    è¿è¡Œè‡ªå®šä¹‰çŠ¶æ€ç¤ºä¾‹
    
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰çŠ¶æ€å’Œäººå·¥å¹²é¢„åŠŸèƒ½
    """
    print("=" * 80)
    print("è‡ªå®šä¹‰çŠ¶æ€æ¼”ç¤º - ä½¿ç”¨ QwenClientï¼ˆé€šä¹‰åƒé—®ï¼‰")
    print("=" * 80)
    print()
    
    # åˆ›å»ºå›¾
    graph = create_custom_state_graph()
    
    # é…ç½®ï¼ˆä½¿ç”¨ thread_id æ¥æ ‡è¯†ä¼šè¯ï¼‰
    config = {"configurable": {"thread_id": "1"}}
    
    # ==================== æ­¥éª¤ 1: æç¤ºèŠå¤©æœºå™¨äºº ====================
    print("æ­¥éª¤ 1: æç¤ºèŠå¤©æœºå™¨äººæŸ¥æ‰¾ LangGraph çš„å‘å¸ƒæ—¥æœŸ")
    print("-" * 80)
    
    user_input = (
        "Can you look up when LangGraph was released? "
        "When you have the answer, use the human_assistance tool for review."
    )
    
    print(f"ç”¨æˆ·è¾“å…¥: {user_input}")
    print()
    
    # æµå¼å¤„ç†å›¾æ›´æ–°
    events = graph.stream(
        {"messages": [{"role": "user", "content": user_input}]},
        config,
        stream_mode="values",
    )
    
    for event in events:
        if "messages" in event:
            event["messages"][-1].pretty_print()
            print()
    
    # ==================== æ­¥éª¤ 2: æ£€æŸ¥çŠ¶æ€ï¼ˆåº”è¯¥è¢«ä¸­æ–­ï¼‰====================
    print("\næ­¥éª¤ 2: æ£€æŸ¥å›¾çš„çŠ¶æ€ï¼ˆåº”è¯¥è¢«ä¸­æ–­ï¼‰")
    print("-" * 80)
    
    snapshot = graph.get_state(config)
    
    print(f"çŠ¶æ€å¿«ç…§ä¿¡æ¯:")
    print(f"  - snapshot.next: {snapshot.next}")
    print(f"  - æ˜¯å¦è¢«ä¸­æ–­: {'æ˜¯' if snapshot.next else 'å¦'}")
    
    if snapshot.values:
        print(f"  - å½“å‰ name: {snapshot.values.get('name', 'N/A')}")
        print(f"  - å½“å‰ birthday: {snapshot.values.get('birthday', 'N/A')}")
    
    # ==================== æ­¥éª¤ 3: æ·»åŠ äººå·¥ååŠ© ====================
    print("\næ­¥éª¤ 3: æ·»åŠ äººå·¥ååŠ©ï¼ˆæä¾›æ­£ç¡®çš„ä¿¡æ¯ï¼‰")
    print("-" * 80)
    
    if not snapshot.next:
        print("âš ï¸  å›¾æ²¡æœ‰è¢«ä¸­æ–­ï¼Œè·³è¿‡äººå·¥å¹²é¢„æ­¥éª¤")
        print()
    else:
        print("âš ï¸  å›¾è¢«ä¸­æ–­ï¼Œéœ€è¦äººå·¥å¹²é¢„")
        print("\nèŠå¤©æœºå™¨äººæœªèƒ½è¯†åˆ«æ­£ç¡®çš„æ—¥æœŸï¼Œå› æ­¤ä¸ºå…¶æä¾›ä¿¡æ¯")
        print("ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šç­‰å¾…çœŸå®çš„äººå·¥è¾“å…¥ï¼‰")
        print()
        
        # èŠå¤©æœºå™¨äººæœªèƒ½è¯†åˆ«æ­£ç¡®çš„æ—¥æœŸï¼Œå› æ­¤ä¸ºå…¶æä¾›ä¿¡æ¯
        # æ³¨æ„ï¼šresume ä¸­çš„å€¼ä¼šè¢«ä¼ é€’ç»™ interrupt() å‡½æ•°ä½œä¸ºè¿”å›å€¼
        # å¦‚æœ resume ä¸­åŒ…å« "correct" å­—æ®µä¸”ä»¥ 'y' å¼€å¤´ï¼Œåˆ™ä½¿ç”¨åŸå§‹å€¼
        # å¦åˆ™ï¼Œä½¿ç”¨ resume ä¸­çš„ "name" å’Œ "birthday" å€¼
        human_command = Command(
            resume={
                "name": "LangGraph",
                "birthday": "Jan 17, 2024",
                # æ³¨æ„ï¼šè¿™é‡Œæ²¡æœ‰ "correct" å­—æ®µï¼Œæ‰€ä»¥ä¼šä½¿ç”¨ resume ä¸­çš„å€¼
            },
        )
        
        print("äººå·¥æä¾›ä¿¡æ¯:")
        print(f"  - name: LangGraph")
        print(f"  - birthday: Jan 17, 2024")
        print()
        
        events = graph.stream(human_command, config, stream_mode="values")
        for event in events:
            if "messages" in event:
                event["messages"][-1].pretty_print()
                print()
    
    # ==================== æ­¥éª¤ 4: æŸ¥çœ‹çŠ¶æ€ä¸­çš„å­—æ®µ ====================
    print("\næ­¥éª¤ 4: æŸ¥çœ‹çŠ¶æ€ä¸­çš„å­—æ®µ")
    print("-" * 80)
    
    snapshot = graph.get_state(config)
    
    # åªæ˜¾ç¤º name å’Œ birthday å­—æ®µ
    state_fields = {k: v for k, v in snapshot.values.items() if k in ("name", "birthday")}
    print(f"çŠ¶æ€ä¸­çš„è‡ªå®šä¹‰å­—æ®µ:")
    for key, value in state_fields.items():
        print(f"  - {key}: {value}")
    
    # ==================== æ­¥éª¤ 5: æ‰‹åŠ¨æ›´æ–°çŠ¶æ€ ====================
    print("\næ­¥éª¤ 5: æ‰‹åŠ¨æ›´æ–°çŠ¶æ€ï¼ˆä½¿ç”¨ graph.update_stateï¼‰")
    print("-" * 80)
    
    # LangGraph å¯¹åº”ç”¨ç¨‹åºçŠ¶æ€æä¾›é«˜åº¦æ§åˆ¶ã€‚
    # ä¾‹å¦‚ï¼Œåœ¨ä»»ä½•æ—¶å€™ï¼ˆåŒ…æ‹¬ä¸­æ–­æ—¶ï¼‰ï¼Œæ‚¨éƒ½å¯ä»¥ä½¿ç”¨ graph.update_state æ‰‹åŠ¨è¦†ç›–ä¸€ä¸ªé”®ã€‚
    result = graph.update_state(config, {"name": "LangGraph (library)"})
    print(f"çŠ¶æ€æ›´æ–°ç»“æœ: {result}")
    
    # ==================== æ­¥éª¤ 6: æŸ¥çœ‹æ–°å€¼ ====================
    print("\næ­¥éª¤ 6: æŸ¥çœ‹æ›´æ–°åçš„çŠ¶æ€å€¼")
    print("-" * 80)
    
    snapshot = graph.get_state(config)
    state_fields = {k: v for k, v in snapshot.values.items() if k in ("name", "birthday")}
    print(f"æ›´æ–°åçš„çŠ¶æ€å­—æ®µ:")
    for key, value in state_fields.items():
        print(f"  - {key}: {value}")
    
    print("\n" + "=" * 80)
    print("æ€»ç»“")
    print("=" * 80)
    print("""
æœ¬æ•™ç¨‹æ¼”ç¤ºäº†ï¼š

1. å‘çŠ¶æ€æ·»åŠ è‡ªå®šä¹‰é”®ï¼ˆname å’Œ birthdayï¼‰
   - ä½¿å…¶ä»–å›¾èŠ‚ç‚¹å’ŒæŒä¹…å±‚æ˜“äºè®¿é—®è¿™äº›ä¿¡æ¯

2. åœ¨å·¥å…·å†…éƒ¨æ›´æ–°çŠ¶æ€
   - ä½¿ç”¨ Command å¯¹è±¡ä»å·¥å…·å†…éƒ¨å‘å‡ºçŠ¶æ€æ›´æ–°
   - ä½¿ç”¨ ToolMessage æ¥æ›´æ–°æ¶ˆæ¯åˆ—è¡¨

3. ä½¿ç”¨ interrupt è¿›è¡Œäººå·¥å¹²é¢„
   - åœ¨å·¥å…·ä¸­è°ƒç”¨ interrupt() æ¥æš‚åœæ‰§è¡Œ
   - ä½¿ç”¨ Command(resume={...}) æ¥æ¢å¤æ‰§è¡Œå¹¶æä¾›æ•°æ®

4. æ‰‹åŠ¨æ›´æ–°çŠ¶æ€
   - ä½¿ç”¨ graph.update_state() åœ¨ä»»ä½•æ—¶å€™æ‰‹åŠ¨è¦†ç›–çŠ¶æ€é”®
   - æ‰‹åŠ¨çŠ¶æ€æ›´æ–°ä¼šåœ¨ LangSmith ä¸­ç”Ÿæˆè¿½è¸ª

5. çŠ¶æ€ç®¡ç†
   - ä½¿ç”¨ graph.get_state() è·å–çŠ¶æ€å¿«ç…§
   - çŠ¶æ€å¿«ç…§åŒ…å« valuesã€nextã€tasksã€interrupts ç­‰ä¿¡æ¯
    """)


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    try:
        run_example()
    except ValueError as e:
        print(f"\nâŒ é…ç½®é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿åœ¨ .env æ–‡ä»¶ä¸­é…ç½®äº† ALIBABA_BAILIAN_API_KEY")
        import traceback
        traceback.print_exc()
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

