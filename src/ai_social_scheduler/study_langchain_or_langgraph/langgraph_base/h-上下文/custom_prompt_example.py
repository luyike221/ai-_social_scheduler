"""
ä½¿ç”¨ä¸Šä¸‹æ–‡è‡ªå®šä¹‰æç¤ºç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•æ ¹æ®é…ç½®æˆ–çŠ¶æ€åŠ¨æ€ç”Ÿæˆæç¤ºã€‚

æ‰§è¡Œå‘½ä»¤ï¼š
uv run python -m ai_social_scheduler.study_langchain_or_langgraph.langgraph_base.h-ä¸Šä¸‹æ–‡.custom_prompt_example

"""

from langchain_core.messages import AnyMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState

from ai_social_scheduler.client import QwenClient


def custom_prompt(
    state: AgentState,
    config: RunnableConfig,
) -> list[AnyMessage]:
    """
    è‡ªå®šä¹‰æç¤ºå‡½æ•°ï¼ˆæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€ç”Ÿæˆï¼‰
    
    åŸç†å’Œæœºåˆ¶ï¼š
    1. LangGraph åœ¨æ¯æ¬¡è°ƒç”¨ LLM ä¹‹å‰ä¼šè°ƒç”¨è¿™ä¸ªå‡½æ•°
    2. å‡½æ•°æ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼š
       - state: å½“å‰çŠ¶æ€ï¼ˆåŒ…å« messages ç­‰ï¼‰
       - config: è¿è¡Œæ—¶é…ç½®ï¼ˆåŒ…å« configurable ä¸­çš„é™æ€æ•°æ®ï¼‰
    3. å‡½æ•°è¿”å›æ¶ˆæ¯åˆ—è¡¨ï¼ŒLangGraph ä¼šå°†è¿™ä¸ªåˆ—è¡¨ä¼ é€’ç»™ LLM
    4. é€šè¿‡åŠ¨æ€ç”Ÿæˆ system messageï¼Œå¯ä»¥å®ç°ï¼š
       - ä¸ªæ€§åŒ–æç¤ºï¼ˆæ ¹æ®ç”¨æˆ·ä¿¡æ¯ï¼‰
       - æ¡ä»¶è¡Œä¸ºï¼ˆæ ¹æ®ç”¨æˆ·è§’è‰²ï¼‰
       - ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼ˆæ ¹æ®çŠ¶æ€ä¿¡æ¯ï¼‰
    
    æ‰§è¡Œæµç¨‹ï¼š
    invoke() -> LangGraph -> custom_prompt(state, config) -> ç”Ÿæˆæ¶ˆæ¯åˆ—è¡¨ -> ä¼ é€’ç»™ LLM
    """
    user_name = config.get("configurable", {}).get("user_name", "ç”¨æˆ·")
    system_msg = f"ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚å½“å‰ç”¨æˆ·çš„åå­—æ˜¯ {user_name}ã€‚è¯·ç”¨å‹å¥½çš„æ–¹å¼ä¸ç”¨æˆ·äº¤æµã€‚"
    
    # è¿”å›çš„æ¶ˆæ¯åˆ—è¡¨ä¼šä¼ é€’ç»™ LLM
    # system message åœ¨æœ€å‰é¢ï¼Œç„¶åæ˜¯ç”¨æˆ·æ¶ˆæ¯
    return [{"role": "system", "content": system_msg}] + state["messages"]


@tool
def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯"""
    weather_data = {
        "åŒ—äº¬": "æ™´æœ—ï¼Œæ¸©åº¦ 25Â°C",
        "ä¸Šæµ·": "å¤šäº‘ï¼Œæ¸©åº¦ 22Â°C",
        "æ·±åœ³": "æ™´æœ—ï¼Œæ¸©åº¦ 28Â°C",
    }
    return f"{city} çš„å¤©æ°”ï¼š{weather_data.get(city, 'æ™´æœ—ï¼Œæ¸©åº¦ 25Â°C')}"


def main():
    """ç¤ºä¾‹ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡è‡ªå®šä¹‰æç¤º"""
    print("=" * 80)
    print("ç¤ºä¾‹ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡è‡ªå®šä¹‰æç¤º")
    print("=" * 80)
    print()
    
    qwen_client = QwenClient(model="qwen-plus", temperature=0.7)
    
    agent = create_react_agent(
        qwen_client.client,
        tools=[get_weather],
        prompt=custom_prompt,  # ä¼ å…¥è‡ªå®šä¹‰æç¤ºå‡½æ•°
    )
    
    print("ğŸ’¡ ä½¿ç”¨è‡ªå®šä¹‰æç¤ºï¼ˆæ ¹æ®ç”¨æˆ·åç§°ï¼‰...")
    # æœºåˆ¶è¯´æ˜ï¼š
    # 1. invoke æ—¶ä¼ å…¥ configï¼ŒåŒ…å« user_name
    # 2. LangGraph æ¯æ¬¡è°ƒç”¨ LLM å‰ä¼šè°ƒç”¨ custom_prompt(state, config)
    # 3. custom_prompt ä» config ä¸­è¯»å– user_nameï¼ŒåŠ¨æ€ç”Ÿæˆ system message
    # 4. ç”Ÿæˆçš„æç¤ºåŒ…å«ä¸ªæ€§åŒ–ä¿¡æ¯ï¼Œå½±å“ LLM çš„è¡Œä¸º
    response = agent.invoke(
        {"messages": [HumanMessage(content="æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”")]},
        config={"configurable": {"user_name": "ç‹äº”"}}  # é…ç½®æ•°æ®ä¼šä¼ é€’ç»™ custom_prompt
    )
    
    if "messages" in response and response["messages"]:
        last_message = response["messages"][-1]
        print(f"é—®é¢˜: æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”")
        print(f"å›ç­”: {last_message.content}")
    
    print()
    print("âœ… è‡ªå®šä¹‰æç¤ºç¤ºä¾‹å®Œæˆ")
    print()


if __name__ == "__main__":
    main()

